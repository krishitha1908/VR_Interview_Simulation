# VR_Interview_Simulation

The Interview Simulation VR Project delivers a highly immersive interview practice environment by leveraging Meta Quest headsets together with Unity3D and OpenXR for robust cross-device support. Utilizing C# scripting for precise interaction logic, the VR client presents a professional interviewer avatar that greets the user with a realistic virtual handshake, complete with collision-driven animation and haptic feedback. Once the user selects a domain (e.g., Software Engineering, Data Science, Embedded Systems) and years of experience through intuitive 3D menus, the system initiates a live interview sequence. Questions are generated dynamically by a Python Flask backend that interfaces with Google’s Gemini API, ensuring that each query is tailored to the candidate’s profile. User responses are captured in real-time via Wit.ai’s speech-to-text service, then evaluated by the same Gemini API for clarity, depth, and relevance.
